# -*- coding: utf-8 -*-
"""feature importance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gbucntlrFW5WOlZJFYsFs_DpdhOEuAge
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance

# 특징 중요도 계산
def calculate_feature_importance(file_path: str):

    # 1. 데이터 불러오기 및 준비
    df = pd.read_csv(file_path)
    X = df.drop(columns=["날짜", "PM10", "PM10_MA7", "PM10_MA30", "PM10lag", "Spring","Summer", "Autumn" ,"Winter" ])   # 입력 변수(Feature) 선택
    y = df["PM10"]

    # 2. 훈련용과 테스트용 데이터로 분리
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 3. 랜덤 포레스트 모델 생성 및 학습
    model = RandomForestRegressor(random_state=42)
    model.fit(X_train, y_train)

    # 4. 지니 중요도(Gini Importance) 계산
    gini_importance = model.feature_importances_                     # 모델의 기본 특징 중요도 추출
    feature_names = X_train.columns
    gini_importance_df = pd.DataFrame({'Feature': feature_names, 'Gini Importance': gini_importance})
    gini_importance_df = gini_importance_df.sort_values(by='Gini Importance', ascending=False) # 중요도 순으로 정렬

    return gini_importance_df

if __name__ == '__main__':

    file_name = "pm10.csv" #pm2.5의 경우 파일과 feature 부분만 수정

    gini_df = calculate_feature_importance(file_name)

    print("--- 중요도 (Importance) ---")
    print(gini_df)