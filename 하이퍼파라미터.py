# -*- coding: utf-8 -*-
"""하이퍼파라미터.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wHtI7te4X4xRFyNdRJEON66X6riC3BV2
"""

!pip install optuna

import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM
from tensorflow.keras.callbacks import EarlyStopping

df2 = pd.read_csv('pm25.csv')
df10 = pd.read_csv('pm10.csv')

# ▶ 사용할 입력 변수 정의 (7일치 시계열 데이터)
features = ['PM10', '오 존', '이산화질소', '일산화탄소', '아황산가스',
            '평균기온(°C)', '평균 풍속(m/s)', '평균 상대습도(%)', '평균 현지기압(hPa)', 'PM2.5_MA7', 'PM2.5_MA30', 'PM2.5lag',
            'Autumn', 'Spring', 'Summer', 'Winter']

# ▶ 입력 데이터를 시퀀스로 변환 (7일 입력 → 다음날 PM2.5 예측)
X, y = [], []
for i in range(7, len(df2)):
    X.append(df2.loc[i-7:i-1, features].values)  # 7일 동안의 입력 데이터
    y.append(df2.loc[i, 'PM2.5'])  # 예측 대상인 PM2.5 값
X = np.array(X)  # 배열 변환
y = np.array(y)

# ▶ 학습/테스트 데이터 분할 (80% 학습 데이터, 20% 테스트 데이터)(단순스플릿)
n_train = int(0.8 * len(X))
X_train, X_test = X[:n_train], X[n_train:]  # 학습 데이터
y_train, y_test = y[:n_train], y[n_train:]  # 테스트 데이터

import optuna
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error
import numpy as np

def objective(trial):
    model = Sequential()

    # 하이퍼파라미터 탐색 공간
    n_units1 = trial.suggest_int('n_units1', 16, 64)
    n_units2 = trial.suggest_int('n_units2', 8, 32)
    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])
    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])
    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])

    # 모델 정의
    model.add(LSTM(n_units1, activation=activation, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(LSTM(n_units2, activation=activation))
    model.add(Dense(1))

    model.compile(optimizer=optimizer, loss='mse')

    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

    history = model.fit(
        X_train, y_train,
        validation_split=0.15,
        epochs=100,
        batch_size=batch_size,
        verbose=0,
        callbacks=[early_stop]
    )

    y_pred = model.predict(X_test).flatten()
    mse = mean_squared_error(y_test, y_pred)
    return mse

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=60, n_jobs=4)

print("Best hyperparameters:", study.best_params)

import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM
from tensorflow.keras.callbacks import EarlyStopping


df2 = pd.read_csv('pm25.csv')
df10 = pd.read_csv('pm10.csv')

# ▶ 사용할 입력 변수 정의 (7일치 시계열 데이터)
features = ['PM2.5', '오 존', '이산화질소', '일산화탄소', '아황산가스',
            '평균기온(°C)', '평균 풍속(m/s)', '평균 상대습도(%)', '평균 현지기압(hPa)', 'PM10_MA7', 'PM10_MA30', 'PM10lag',
            'Autumn', 'Spring', 'Summer', 'Winter']

# ▶ 입력 데이터를 시퀀스로 변환 (7일 입력 → 다음날 PM2.5 예측)
X, y = [], []
for i in range(7, len(df2)):
    X.append(df2.loc[i-7:i-1, features].values)  # 7일 동안의 입력 데이터
    y.append(df2.loc[i, 'PM10'])  # 예측 대상인 PM2.5 값
X = np.array(X)  # 배열 변환
y = np.array(y)

# ▶ 학습/테스트 데이터 분할 (80% 학습 데이터, 20% 테스트 데이터)(단순스플릿)
n_train = int(0.8 * len(X))
X_train, X_test = X[:n_train], X[n_train:]  # 학습 데이터
y_train, y_test = y[:n_train], y[n_train:]  # 테스트 데이터

import optuna
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error
import numpy as np

def objective(trial):
    model = Sequential()

    # 하이퍼파라미터 탐색 공간
    n_units1 = trial.suggest_int('n_units1', 16, 64)
    n_units2 = trial.suggest_int('n_units2', 8, 32)
    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])
    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])
    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])

    # 모델 정의
    model.add(LSTM(n_units1, activation=activation, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(LSTM(n_units2, activation=activation))
    model.add(Dense(1))

    model.compile(optimizer=optimizer, loss='mse')

    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

    history = model.fit(
        X_train, y_train,
        validation_split=0.15,
        epochs=100,
        batch_size=batch_size,
        verbose=0,
        callbacks=[early_stop]
    )

    y_pred = model.predict(X_test).flatten()
    mse = mean_squared_error(y_test, y_pred)
    return mse

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=60, n_jobs=4)

print("Best hyperparameters:", study.best_params)